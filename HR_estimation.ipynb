{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/pouya/.local/lib/python3.8/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/lib/python3/dist-packages (from opencv-python) (1.17.4)\n",
      "Requirement already satisfied: imutils in /home/pouya/.local/lib/python3.8/site-packages (0.5.4)\n",
      "Requirement already satisfied: scipy in /home/pouya/.local/lib/python3.8/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/lib/python3/dist-packages (from scipy) (1.17.4)\n",
      "Collecting kivymd\n",
      "  Downloading kivymd-0.104.2-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 183 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/lib/python3/dist-packages (from kivymd) (7.0.0)\n",
      "Collecting kivy>=2.0.0\n",
      "  Downloading Kivy-2.0.0-cp38-cp38-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 115 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Kivy-Garden>=0.1.4\n",
      "  Using cached kivy-garden-0.1.4.tar.gz (6.8 kB)\n",
      "Collecting docutils\n",
      "  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
      "\u001b[K     |████████████████████████████████| 575 kB 130 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pygments in /usr/lib/python3/dist-packages (from kivy>=2.0.0->kivymd) (2.3.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from Kivy-Garden>=0.1.4->kivy>=2.0.0->kivymd) (2.22.0)\n",
      "Building wheels for collected packages: Kivy-Garden\n",
      "  Building wheel for Kivy-Garden (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Kivy-Garden: filename=Kivy_Garden-0.1.4-py3-none-any.whl size=4531 sha256=16b6d8bd3c63774dbc6c8a6f4ba33808b1f2aac529659bc284846bc7480bc181\n",
      "  Stored in directory: /home/pouya/.cache/pip/wheels/d2/72/1a/9ddd17f00755707937caa350616965fb3330a6270425f397e6\n",
      "Successfully built Kivy-Garden\n",
      "Installing collected packages: Kivy-Garden, docutils, kivy, kivymd\n",
      "Successfully installed Kivy-Garden-0.1.4 docutils-0.17.1 kivy-2.0.0 kivymd-0.104.2\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install opencv-python\n",
    "!python3 -m pip install imutils\n",
    "!python3 -m pip install scipy\n",
    "!python3 -m pip install kivymd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "# fa = face_utils.FaceAligner(predictor, desiredFaceWidth=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [0.4573941230773926, 0.5243048667907715, 0.5884156227111816, 0.6598880290985107, 0.7261257171630859, 0.7935934066772461, 0.8618490695953369, 0.9263031482696533, 0.9928390979766846, 1.0607123374938965, 1.1237776279449463, 1.1914820671081543, 1.2601053714752197, 1.3237175941467285, 1.3914439678192139, 1.4603352546691895, 1.5236155986785889, 1.5936810970306396, 1.6621437072753906, 1.7242372035980225, 1.7914845943450928, 1.8629605770111084, 1.9265611171722412, 1.9942429065704346, 2.0627574920654297, 2.1286895275115967, 2.192129135131836, 2.2594246864318848, 2.326779842376709, 2.397487163543701, 2.460686206817627, 2.5290303230285645, 2.602142095565796, 2.6607887744903564, 2.727782964706421, 2.797205924987793, 2.869267463684082, 2.9277684688568115, 2.9965527057647705, 3.063271999359131, 3.1276726722717285, 3.1966631412506104, 3.2638580799102783, 3.3359742164611816, 3.3945250511169434, 3.4696097373962402, 3.531897783279419, 3.596130609512329, 3.664821147918701, 3.7321441173553467, 3.794802665710449, 3.86594557762146, 3.9348957538604736, 4.000079393386841, 4.067004680633545, 4.13087010383606, 4.199794769287109, 4.26450777053833, 4.331776857376099, 4.39981746673584, 4.470014572143555, 4.531943082809448, 4.600418567657471, 4.667673826217651, 4.731394529342651, 4.8003249168396, 4.8690619468688965, 4.937388181686401, 4.9999401569366455, 5.067350387573242, 5.135463237762451, 5.199345588684082, 5.267485857009888, 5.336625337600708, 5.409091234207153, 5.469179630279541, 5.538147211074829, 5.602144718170166, 5.667215824127197, 5.73421573638916, 5.803366184234619, 5.872560262680054, 5.936913728713989, 6.005550146102905, 6.071615934371948, 6.135164737701416, 6.2039923667907715, 6.274175643920898, 6.335222959518433, 6.4032487869262695, 6.474201202392578, 6.539541482925415, 6.602487564086914, 6.671722173690796, 6.73976993560791, 6.803497314453125, 6.872542381286621, 6.941556453704834, 7.008325815200806, 7.072098255157471, 7.139697313308716, 7.206878900527954, 7.271030426025391, 7.339463472366333, 7.40746808052063, 7.475736379623413, 7.539863586425781, 7.608581304550171, 7.675726652145386, 7.739495754241943, 7.8068687915802, 7.876708030700684, 7.938722133636475, 8.008517503738403, 8.086267709732056, 8.143656492233276, 8.208364248275757, 8.278966426849365, 8.344727516174316, 8.407656192779541, 8.475274085998535, 8.542881727218628, 8.611860036849976, 8.674273490905762, 8.743529796600342, 8.811385154724121, 8.875312089920044, 8.943866491317749]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing Realt Time Heart Rate Monitoring From Facial RGB Color Video Using Webcam H.Rahman, M.U Ahmed\n",
    "\n",
    "def process(data_buffer, times, bmps):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Detrending\n",
    "    Remove unwanted trend from series\n",
    "    the collected RGB signals will be drfting and noising\n",
    "    \n",
    "    \"\"\"\n",
    "    data_buffer = signal.detrend(data_buffer, axis=0)\n",
    "    \n",
    "    \n",
    "    # Filtering\n",
    "    filter_ = np.hamming(128) * 1.4 + 0.6\n",
    "#     filter_ = filter_.reshape(128, 1)\n",
    "    x_filtered = filter_ * data_buffer\n",
    "    \n",
    "    # Normalization\n",
    "#     data_buffer_normalized = (x_filtered - x_filtered.mean()) \\\n",
    "#                                     / x_filtered.std()\n",
    "    \n",
    "    data_buffer_normalized = x_filtered / np.linalg.norm(x_filtered)\n",
    "    \n",
    "    fft = np.fft.fft(data_buffer_normalized * 10)\n",
    "    fft = np.abs(fft) ** 2\n",
    "    \n",
    "    times_ = np.array(times)\n",
    "    \n",
    "    selected_freq = (times_ > 0.75) & (times_ < 3)\n",
    "    times_ = times_[selected_freq]\n",
    "    \n",
    "#     plt.plot(times_, fft[selected_freq][:, 0])\n",
    "    \n",
    "    bpm = len(signal.find_peaks(fft[selected_freq][:])[0]) / (times[-1] - times[0]) * 60\n",
    "    \n",
    "    bpms.append(bpm)\n",
    "    \n",
    "    print (str(np.mean(np.array(bpms))), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Heart Rate From Video Isabel Bush Stanford\n",
    "\n",
    "# def process1(data_buffer):\n",
    "    \n",
    "#     length = times[-1] - times[0]\n",
    "\n",
    "#     fps = len(data_buffer) / length\n",
    "    \n",
    "#     detrend = signal.detrend(data_buffer.mean(axis=1))\n",
    "\n",
    "#     normalized = (detrend - detrend.mean()) / detrend.std() \n",
    "\n",
    "#     filtered = (np.hamming(buffer_size) * 1.4 + 0.6) * normalized \n",
    "\n",
    "#     fft = np.fft.rfft(filtered)\n",
    "    \n",
    "# #     plt.plot(fft)\n",
    "    \n",
    "#     peaks_index = signal.find_peaks(fft)[0] \n",
    "    \n",
    "#     peaks_in_range = np.sum((fft[peaks_index] > 0.75) & (fft[peaks_index] < 4)) \n",
    "    \n",
    "#     print((peaks_in_range / length) * 60)\n",
    "\n",
    "#     times_ = np.array(times)\n",
    "    \n",
    "#     times__ = times_[(times_ > 0.75) & (times_ < 4)]\n",
    "\n",
    "#     fft_red = fft[:, 0][(times_ > 0.75) & (times_ < 4)]\n",
    "#     fft_green = fft[:, 1][(times_ > 0.75) & (times_ < 4)]\n",
    "#     fft_blue = fft[:, 2][(times_ > 0.75) & (times_ < 4)]\n",
    "\n",
    "#     bpms.append(times__[np.argmax(fft_red)] * 60)\n",
    "#     bpms.append(times__[np.argmax(fft_green)] * 60)\n",
    "#     print(np.array(bmps[-30:]).mean())\n",
    "    # print(times[np.argmax(fft_blue)] * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/lib/python3/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.779582176130874\r"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ff386c4513a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(\"video.webm\")\n",
    "\n",
    "data_buffer = []\n",
    "# times = []\n",
    "bpms = []\n",
    "buffer_size = 128\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "if vc.isOpened():\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "    \n",
    "while rval:\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    if len(rects) > 0:\n",
    "        \n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rects[0])\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        face_frame = frame[y: y + h, x: x + w]\n",
    "        \n",
    "        \n",
    "        grayf = cv2.cvtColor(face_frame, cv2.COLOR_BGR2GRAY)\n",
    "        shape = predictor(grayf, rects[0])\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        cv2.rectangle(frame,(shape[54][0], shape[29][1]), #draw rectangle on right and left cheeks\n",
    "                        (shape[12][0],shape[33][1]), (0,50,50), 0)\n",
    "        \n",
    "        cv2.rectangle(frame, (shape[4][0], shape[29][1]), \n",
    "                        (shape[48][0],shape[33][1]), (0,255,0), 0)\n",
    "        \n",
    "        \n",
    "#         for (a, b) in shape:\n",
    "#             cv2.circle(frame, (a, b), 1, (0, 0, 255), -1) #draw facial landmarks\n",
    "        \n",
    "#         for (a,b) in [(shape[18][0], shape[18][1]), (shape[25][0], shape[25][1] - 10)]:\n",
    "#             cv2.circle(frame, (a, b), 1, (0, 0, 255), -1)\n",
    "        \n",
    "#         forehead = {\n",
    "#             \"upper_x\": shape[18][0], \n",
    "#             \"upper_y\": shape[18][1] - int(0.25 * h),\n",
    "#             \"lower_x\": shape[25][0],\n",
    "#             \"lower_y\": shape[25][1] - 20}\n",
    "        \n",
    "#         cv2.rectangle(frame, (forehead[\"upper_x\"], forehead[\"upper_y\"]), (forehead[\"lower_x\"], forehead[\"lower_y\"]), (0, 50, 50), 0) \n",
    "    \n",
    "    \n",
    "        ROI1 = frame[shape[29][1]:shape[33][1], shape[54][0]: shape[12][0]] # right chin\n",
    "#         ROI2 = frame[forehead[\"upper_y\"]: forehead[\"lower_y\"], forehead[\"upper_x\"]: forehead[\"lower_x\"]]\n",
    "        \n",
    "#         ROI2 = frame[shape[29][1]: shape[33][1], shape[4][0]:shape[48][0]]\n",
    "        \n",
    "#         print(ROI1 + ROI2 / 2)\n",
    "        \n",
    "        mean = ROI1.mean(axis=(0, 1))\n",
    "        \n",
    "        g = mean[1]\n",
    "        \n",
    "        if (abs(mean[1] - np.mean(data_buffer)) > 10) and (len(data_buffer) > 99):\n",
    "           g = data_buffer[-1]\n",
    "        \n",
    "        data_buffer.append(g)\n",
    "        \n",
    "#         times.append(time.time() - t0)\n",
    "        \n",
    "        \n",
    "        if len(data_buffer) > 128 :\n",
    "            \n",
    "            data_buffer = data_buffer[-buffer_size:]\n",
    "            \n",
    "#             times = times[-buffer_size:]\n",
    "            \n",
    "#             times[1:] = times[1:] - times[0]\n",
    "            \n",
    "            process(np.array(data_buffer), times, bpms)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        cv2.putText(frame, \"No FACE DETECTED\", (65, 220), cv2.FONT_HERSHEY_PLAIN, 2, (0, 256, 256))\n",
    "    \n",
    "    \n",
    "    if key == 27: # Exit on Escape\n",
    "        break\n",
    "cv2.destroyWindow(\"preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
